from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field
from typing import Optional, Dict, List, Any
from datetime import datetime, date
import os
import uuid
import logging

# BigQuery direkt importieren
try:
    from google.cloud import bigquery
    BIGQUERY_AVAILABLE = True
    logger = logging.getLogger(__name__)
    logger.info("✅ BigQuery verfügbar")
except ImportError:
    BIGQUERY_AVAILABLE = False
    logger = logging.getLogger(__name__)
    logger.warning("⚠️ BigQuery nicht verfügbar")

# Logging konfigurieren
logging.basicConfig(level=logging.INFO)

app = FastAPI(
    title="RA Autohaus Tracker API",
    description="Multi-Source Fahrzeugprozess-Tracking für Reinhardt Automobile", 
    version="1.0.0"
)

# BigQuery Client (falls verfügbar)
if BIGQUERY_AVAILABLE:
    try:
        bq_client = bigquery.Client(project="ra-autohaus-tracker")
        logger.info("BigQuery Client initialisiert")
    except Exception as e:
        logger.error(f"BigQuery Client Fehler: {e}")
        bq_client = None
else:
    bq_client = None

# In-Memory Fallback
vehicles_db = {}
processes_db = {}

class VehicleCreate(BaseModel):
    fin: str = Field(..., min_length=17, max_length=17)
    marke: str
    modell: str
    antriebsart: str
    farbe: str
    baujahr: Optional[int] = None

class ProcessCreate(BaseModel):
    fin: str = Field(..., min_length=17, max_length=17)
    prozess_typ: str
    bearbeiter: Optional[str] = None
    prioritaet: Optional[int] = Field(5, ge=1, le=10)
    anlieferung_datum: Optional[date] = None
    notizen: Optional[str] = None

class ProcessUpdate(BaseModel):
    status: str
    bearbeiter: Optional[str] = None
    notizen: Optional[str] = None

async def save_vehicle_to_bigquery(vehicle_data: dict) -> bool:
    """Fahrzeug in BigQuery speichern (mit korrekter DateTime-Behandlung)"""
    if not bq_client:
        logger.warning("BigQuery Client nicht verfügbar")
        return False
    
    try:
        table_id = "ra-autohaus-tracker.autohaus.fahrzeuge_stamm"
        table = bq_client.get_table(table_id)
        
        # DateTime korrekt für BigQuery formatieren
        now_iso = datetime.now().isoformat()
        
        row = {
            "fin": vehicle_data["fin"],
            "marke": vehicle_data["marke"],
            "modell": vehicle_data["modell"],
            "antriebsart": vehicle_data["antriebsart"],
            "farbe": vehicle_data["farbe"],
            "baujahr": vehicle_data.get("baujahr"),
            "ersterfassung_datum": now_iso,  # Als ISO String
            "aktiv": True
        }
        
        # None-Werte entfernen (BigQuery mag keine None in JSON)
        row = {k: v for k, v in row.items() if v is not None}
        
        logger.info(f"Inserting into BigQuery: {row}")
        
        errors = bq_client.insert_rows_json(table, [row])
        if errors:
            logger.error(f"BigQuery errors: {errors}")
            return False
        
        logger.info(f"✅ Vehicle saved to BigQuery: {vehicle_data['fin']}")
        return True
        
    except Exception as e:
        logger.error(f"❌ BigQuery save error: {e}")
        return False

async def save_process_to_bigquery(process_data: dict) -> bool:
    """Prozess in BigQuery speichern"""
    if not bq_client:
        return False
    
    try:
        table_id = "ra-autohaus-tracker.autohaus.fahrzeug_prozesse"
        table = bq_client.get_table(table_id)
        
        # DateTime-Objekte zu ISO Strings konvertieren
        row = {}
        for key, value in process_data.items():
            if isinstance(value, datetime):
                row[key] = value.isoformat()
            elif isinstance(value, date):
                row[key] = value.isoformat()
            elif value is not None:
                row[key] = value
        
        # Zusätzliche Felder für BigQuery
        if "erstellt_am" not in row:
            row["erstellt_am"] = datetime.now().isoformat()
        
        logger.info(f"Inserting process into BigQuery: {row}")
        
        errors = bq_client.insert_rows_json(table, [row])
        if errors:
            logger.error(f"BigQuery process errors: {errors}")
            return False
        
        logger.info(f"✅ Process saved to BigQuery: {process_data['prozess_id']}")
        return True
        
    except Exception as e:
        logger.error(f"❌ BigQuery process save error: {e}")
        return False

@app.get("/")
async def root():
    return {
        "message": "RA Autohaus Tracker API",
        "version": "1.0.0",
        "docs": "/docs",
        "bigquery_available": BIGQUERY_AVAILABLE
    }

@app.get("/health")
async def health_check():
    """Health Check mit BigQuery Status"""
    bigquery_status = "healthy" if bq_client else "unavailable"
    
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "environment": os.getenv("ENVIRONMENT", "development"),
        "services": {
            "api": "healthy",
            "bigquery": bigquery_status,
            "bigquery_available": BIGQUERY_AVAILABLE
        }
    }

@app.post("/fahrzeuge", status_code=201)
async def create_fahrzeug(fahrzeug: VehicleCreate):
    """Fahrzeug anlegen (BigQuery + Memory Fallback)"""
    try:
        # Versuche BigQuery zuerst
        bigquery_success = await save_vehicle_to_bigquery(fahrzeug.dict())
        
        # Fallback: In-Memory speichern falls BigQuery fehlschlägt
        if not bigquery_success:
            logger.warning("BigQuery speichern fehlgeschlagen, verwende Memory")
            vehicles_db[fahrzeug.fin] = {
                **fahrzeug.dict(),
                "erstellt_am": datetime.now().isoformat()
            }
        
        return {
            "message": "Fahrzeug erfolgreich angelegt",
            "fin": fahrzeug.fin,
            "storage": "bigquery" if bigquery_success else "memory"
        }
        
    except Exception as e:
        logger.error(f"Error creating vehicle: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/fahrzeuge")
async def list_fahrzeuge():
    """Fahrzeuge auflisten"""
    if bq_client:
        try:
            query = """
            SELECT * FROM `ra-autohaus-tracker.autohaus.fahrzeuge_stamm`
            WHERE aktiv = TRUE
            ORDER BY ersterfassung_datum DESC
            LIMIT 50
            """
            result = bq_client.query(query)
            vehicles = [dict(row) for row in result]
            
            return {
                "fahrzeuge": vehicles,
                "anzahl": len(vehicles),
                "source": "bigquery"
            }
        except Exception as e:
            logger.error(f"BigQuery query error: {e}")
    
    # Fallback: Memory
    return {
        "fahrzeuge": list(vehicles_db.values()),
        "anzahl": len(vehicles_db),
        "source": "memory"
    }

@app.get("/fahrzeuge/{fin}")
async def get_fahrzeug(fin: str):
    """Einzelnes Fahrzeug abrufen"""
    if bq_client:
        try:
            query = """
            SELECT * FROM `ra-autohaus-tracker.autohaus.fahrzeuge_stamm`
            WHERE fin = @fin AND aktiv = TRUE
            """
            job_config = bigquery.QueryJobConfig(
                query_parameters=[
                    bigquery.ScalarQueryParameter("fin", "STRING", fin)
                ]
            )
            result = bq_client.query(query, job_config=job_config)
            vehicles = [dict(row) for row in result]
            
            if vehicles:
                return vehicles[0]
                
        except Exception as e:
            logger.error(f"BigQuery query error: {e}")
    
    # Fallback: Memory
    if fin in vehicles_db:
        return vehicles_db[fin]
    
    raise HTTPException(status_code=404, detail="Fahrzeug nicht gefunden")

@app.post("/prozesse/start", status_code=201)
async def start_prozess(prozess: ProcessCreate):
    """Neuen Prozess starten"""
    try:
        prozess_id = str(uuid.uuid4())
        
        process_data = {
            "prozess_id": prozess_id,
            **prozess.dict(),
            "status": "gestartet",
            "start_timestamp": datetime.now(),
            "datenquelle": "api"
        }
        
        # Versuche BigQuery
        bigquery_success = await save_process_to_bigquery(process_data)
        
        # Fallback: Memory
        if not bigquery_success:
            logger.warning("BigQuery Process speichern fehlgeschlagen, verwende Memory")
            processes_db[prozess_id] = {
                **process_data,
                "start_timestamp": process_data["start_timestamp"].isoformat()
            }
        
        return {
            "message": "Prozess erfolgreich gestartet",
            "prozess_id": prozess_id,
            "fin": prozess.fin,
            "prozess_typ": prozess.prozess_typ,
            "storage": "bigquery" if bigquery_success else "memory"
        }
        
    except Exception as e:
        logger.error(f"Error starting process: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/dashboard/kpis")
async def get_dashboard_kpis():
    """Dashboard KPIs"""
    if bq_client:
        try:
            # BigQuery KPIs
            query = """
            SELECT 
              COUNT(DISTINCT fin) as total_vehicles,
              COUNT(*) as total_records
            FROM `ra-autohaus-tracker.autohaus.fahrzeuge_stamm`
            WHERE aktiv = TRUE
            """
            result = bq_client.query(query)
            rows = list(result)
            
            if rows:
                return dict(rows[0])
                
        except Exception as e:
            logger.error(f"BigQuery KPI error: {e}")
    
    # Memory Fallback
    return {
        "total_vehicles": len(vehicles_db),
        "total_processes": len(processes_db),
        "source": "memory"
    }

# Debug Endpoints
@app.get("/debug/bigquery-info")
async def debug_bigquery_info():
    """Detaillierte BigQuery Debug-Informationen"""
    if not bq_client:
        return {"error": "BigQuery Client nicht verfügbar"}
    
    try:
        info = {
            "project": bq_client.project,
            "location": bq_client.location
        }
        
        # Dataset prüfen
        dataset = bq_client.get_dataset("autohaus")
        info["dataset"] = {
            "dataset_id": dataset.dataset_id,
            "location": dataset.location
        }
        
        # Tabellen auflisten
        tables = list(bq_client.list_tables("autohaus"))
        info["tables"] = [table.table_id for table in tables]
        
        return info
        
    except Exception as e:
        return {"error": f"BigQuery Debug Fehler: {e}"}

@app.post("/debug/bigquery-insert")
async def debug_bigquery_insert():
    """Test-Insert in BigQuery mit korrekter DateTime-Behandlung"""
    if not bq_client:
        return {"error": "BigQuery Client nicht verfügbar"}
    
    try:
        table_id = "ra-autohaus-tracker.autohaus.fahrzeuge_stamm"
        table = bq_client.get_table(table_id)
        
        test_fin = f"DEBUG{datetime.now().strftime('%Y%m%d%H%M%S')}"
        
        test_row = {
            "fin": test_fin,
            "marke": "Debug",
            "modell": "Test",
            "antriebsart": "Debug",
            "farbe": "Debug",
            "baujahr": 2024,
            "ersterfassung_datum": datetime.now().isoformat(),  # Als ISO String!
            "aktiv": True
        }
        
        logger.info(f"Debug insert row: {test_row}")
        
        errors = bq_client.insert_rows_json(table, [test_row])
        
        if errors:
            return {"status": "error", "errors": errors}
        else:
            return {"status": "success", "test_fin": test_fin, "message": "Debug-Insert erfolgreich"}
            
    except Exception as e:
        logger.error(f"Debug insert error: {e}")
        return {"status": "exception", "error": str(e)}

@app.get("/debug/clear-memory")
async def clear_memory():
    """Memory-Storage leeren für Tests"""
    global vehicles_db, processes_db
    vehicles_db.clear()
    processes_db.clear()
    return {"message": "Memory-Storage geleert"}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8080)
async def update_process_in_bigquery(prozess_id: str, update_data: Dict[str, Any]) -> bool:
    """Prozess in BigQuery aktualisieren"""
    if not bq_client:
        return False
    
    try:
        # Update Query bauen
        set_clauses = []
        query_params = [bigquery.ScalarQueryParameter("prozess_id", "STRING", prozess_id)]
        
        for key, value in update_data.items():
            if value is not None and key not in ['prozess_id']:
                set_clauses.append(f"{key} = @{key}")
                
                # Parameter-Typ bestimmen
                if isinstance(value, str):
                    param_type = "STRING"
                elif isinstance(value, int):
                    param_type = "INT64"
                elif isinstance(value, datetime):
                    param_type = "DATETIME"
                    value = value.isoformat()
                else:
                    param_type = "STRING"
                    value = str(value)
                
                query_params.append(bigquery.ScalarQueryParameter(key, param_type, value))
        
        if not set_clauses:
            logger.warning("Keine Update-Daten provided")
            return False
        
        # Aktualisierungs-Timestamp hinzufügen
        set_clauses.append("aktualisiert_am = CURRENT_DATETIME()")
        
        query = f"""
        UPDATE `ra-autohaus-tracker.autohaus.fahrzeug_prozesse`
        SET {', '.join(set_clauses)}
        WHERE prozess_id = @prozess_id
        """
        
        job_config = bigquery.QueryJobConfig(query_parameters=query_params)
        
        query_job = bq_client.query(query, job_config=job_config)
        query_job.result()  # Warten bis Update abgeschlossen
        
        logger.info(f"✅ Prozess in BigQuery aktualisiert: {prozess_id}")
        return True
        
    except Exception as e:
        logger.error(f"❌ Prozess-Update Fehler: {e}")
        return False

@app.put("/prozesse/{prozess_id}")
async def update_prozess(prozess_id: str, update: ProcessUpdate):
    """Prozess-Status in BigQuery aktualisieren"""
    try:
        update_data = update.dict(exclude_unset=True)
        
        # Bei Abschluss End-Timestamp setzen
        if update.status == "abgeschlossen":
            update_data["ende_timestamp"] = datetime.now()
        
        success = await update_process_in_bigquery(prozess_id, update_data)
        
        if not success:
            # Fallback: In Memory suchen und updaten
            if prozess_id in processes_db:
                processes_db[prozess_id].update(update_data)
                success = True
            else:
                raise HTTPException(status_code=404, detail="Prozess nicht gefunden")
        
        return {
            "message": "Prozess erfolgreich aktualisiert",
            "prozess_id": prozess_id,
            "status": update.status,
            "storage": "bigquery" if success else "memory"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error updating process: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/prozesse/{prozess_id}")
async def get_prozess(prozess_id: str):
    """Einzelnen Prozess abrufen"""
    if bq_client:
        try:
            query = """
            SELECT * FROM `ra-autohaus-tracker.autohaus.fahrzeug_prozesse`
            WHERE prozess_id = @prozess_id
            """
            job_config = bigquery.QueryJobConfig(
                query_parameters=[
                    bigquery.ScalarQueryParameter("prozess_id", "STRING", prozess_id)
                ]
            )
            result = bq_client.query(query, job_config=job_config)
            processes = [dict(row) for row in result]
            
            if processes:
                return processes[0]
                
        except Exception as e:
            logger.error(f"BigQuery process query error: {e}")
    
    # Fallback: Memory
    if prozess_id in processes_db:
        return processes_db[prozess_id]
    
    raise HTTPException(status_code=404, detail="Prozess nicht gefunden")

@app.get("/prozesse")
async def list_prozesse(fin: Optional[str] = None, status: Optional[str] = None, limit: int = 50):
    """Alle Prozesse auflisten mit optionaler Filterung"""
    if bq_client:
        try:
            where_clauses = []
            query_params = []
            
            if fin:
                where_clauses.append("fin = @fin")
                query_params.append(bigquery.ScalarQueryParameter("fin", "STRING", fin))
            
            if status:
                where_clauses.append("status = @status")
                query_params.append(bigquery.ScalarQueryParameter("status", "STRING", status))
            
            where_clause = " AND ".join(where_clauses) if where_clauses else "1=1"
            
            query = f"""
            SELECT * FROM `ra-autohaus-tracker.autohaus.fahrzeug_prozesse`
            WHERE {where_clause}
            ORDER BY erstellt_am DESC
            LIMIT {limit}
            """
            
            job_config = bigquery.QueryJobConfig(query_parameters=query_params) if query_params else None
            result = bq_client.query(query, job_config=job_config)
            processes = [dict(row) for row in result]
            
            return {
                "prozesse": processes,
                "anzahl": len(processes),
                "source": "bigquery"
            }
                
        except Exception as e:
            logger.error(f"BigQuery processes query error: {e}")
    
    # Memory Fallback
    filtered = list(processes_db.values())
    if fin:
        filtered = [p for p in filtered if p.get("fin") == fin]
    if status:
        filtered = [p for p in filtered if p.get("status") == status]
    
    return {
        "prozesse": filtered[:limit],
        "anzahl": len(filtered),
        "source": "memory"
    }

@app.get("/debug/prozesse/search/{prozess_id}")
async def debug_prozess_search(prozess_id: str):
    """Debug: Prozess in BigQuery und Memory suchen"""
    result = {
        "prozess_id": prozess_id,
        "bigquery": None,
        "memory": None
    }
    
    # BigQuery suchen
    if bq_client:
        try:
            query = """
            SELECT * FROM `ra-autohaus-tracker.autohaus.fahrzeug_prozesse`
            WHERE prozess_id = @prozess_id
            """
            job_config = bigquery.QueryJobConfig(
                query_parameters=[
                    bigquery.ScalarQueryParameter("prozess_id", "STRING", prozess_id)
                ]
            )
            bq_result = bq_client.query(query, job_config=job_config)
            processes = [dict(row) for row in bq_result]
            
            result["bigquery"] = processes[0] if processes else "nicht_gefunden"
            
        except Exception as e:
            result["bigquery"] = f"fehler: {e}"
    
    # Memory suchen
    if prozess_id in processes_db:
        result["memory"] = processes_db[prozess_id]
    else:
        result["memory"] = "nicht_gefunden"
    
    return result
